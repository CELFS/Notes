<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-machine_learning/Task02" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Task02 | 编程内外</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://CELFS.github.io/Notes/img/logo.png"><meta data-rh="true" name="twitter:image" content="https://CELFS.github.io/Notes/img/logo.png"><meta data-rh="true" property="og:url" content="https://CELFS.github.io/Notes/docs/machine_learning/Task02"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Task02 | 编程内外"><meta data-rh="true" name="description" content="2.0 模型评估与选择—概念树"><meta data-rh="true" property="og:description" content="2.0 模型评估与选择—概念树"><link data-rh="true" rel="icon" href="/Notes/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://CELFS.github.io/Notes/docs/machine_learning/Task02"><link data-rh="true" rel="alternate" href="https://CELFS.github.io/Notes/docs/machine_learning/Task02" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://CELFS.github.io/Notes/docs/machine_learning/Task02" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous"><link rel="stylesheet" href="/Notes/assets/css/styles.67339a6f.css">
<script src="/Notes/assets/js/runtime~main.793c07bf.js" defer="defer"></script>
<script src="/Notes/assets/js/main.ef11fa70.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/Notes/img/logo.png"><div role="region" aria-label="跳到主要内容"><a class="skipToContent__HuA" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Notes/"><div class="navbar__logo"><img src="/Notes/img/logo.png" alt="Notes Logo" class="themedComponent_Exct themedComponent--light_c3lc"><img src="/Notes/img/logo.png" alt="Notes Logo" class="themedComponent_Exct themedComponent--dark_Ji9V"></div><b class="navbar__title text--truncate">编程内外</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Notes/docs/category/linux-os">Notes</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/CELFS/Notes" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link" icon="github">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_OqSl"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_OAgU colorModeToggle_zRe0"><button class="clean-btn toggleButton_aClM toggleButtonDisabled_GkIb" type="button" disabled="" title="切换浅色/暗黑模式（当前为暗黑模式）" aria-label="切换浅色/暗黑模式（当前为暗黑模式）" aria-live="polite" aria-pressed="true"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_zzlY"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_Z832"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Cx4E"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_liLQ"><div class="docsWrapper_evXH"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_nZiY" type="button"></button><div class="docRoot_jKp6"><aside class="theme-doc-sidebar-container docSidebarContainer_wXyP"><div class="sidebarViewport_LQZ0"><div class="sidebar_T0dy"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_WBBB"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/linux-os">Linux OS</a><button aria-label="展开侧边栏分类 &#x27;Linux OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/ajax">Ajax</a><button aria-label="展开侧边栏分类 &#x27;Ajax&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/css">CSS</a><button aria-label="展开侧边栏分类 &#x27;CSS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/javascript-es6">JavaScript ES6</a><button aria-label="展开侧边栏分类 &#x27;JavaScript ES6&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/javascript">JavaScript</a><button aria-label="展开侧边栏分类 &#x27;JavaScript&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/nodejs">Node.js</a><button aria-label="展开侧边栏分类 &#x27;Node.js&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/typescript">TypeScript</a><button aria-label="展开侧边栏分类 &#x27;TypeScript&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/vue">Vue</a><button aria-label="展开侧边栏分类 &#x27;Vue&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/轻量级服务器开发tinywebserver">轻量级服务器开发（TinyWebServer）</a><button aria-label="展开侧边栏分类 &#x27;轻量级服务器开发（TinyWebServer）&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/c-后台服务器开发">C++ 后台服务器开发</a><button aria-label="展开侧边栏分类 &#x27;C++ 后台服务器开发&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/mysql-必知必会">MySQL 必知必会</a><button aria-label="展开侧边栏分类 &#x27;MySQL 必知必会&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/操作系统导论">操作系统导论</a><button aria-label="展开侧边栏分类 &#x27;操作系统导论&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/qt">QT</a><button aria-label="展开侧边栏分类 &#x27;QT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/读吴军信息论-40-讲">读吴军《信息论 40 讲》</a><button aria-label="展开侧边栏分类 &#x27;读吴军《信息论 40 讲》&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/读吴军富足">读吴军《富足》</a><button aria-label="展开侧边栏分类 &#x27;读吴军《富足》&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/machine-learning-andrew-ng">Machine Learning (Andrew Ng)</a><button aria-label="展开侧边栏分类 &#x27;Machine Learning (Andrew Ng)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/Notes/docs/category/机器学习初步周志华">机器学习初步（周志华）</a><button aria-label="折叠侧边栏分类 &#x27;机器学习初步（周志华）&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/machine_learning/Task00">Task00</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/machine_learning/Task01">Task01</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Notes/docs/machine_learning/Task02">Task02</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/machine_learning/Task03">Task03</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/machine_learning/Task04">Task04</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/machine_learning/Task05">Task05</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/machine_learning/Task06">Task06</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/machine_learning/Task07">Task07</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/machine_learning/Task08">Task08</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/paddle-零基础深度学习第二版">Paddle 零基础深度学习（第二版）</a><button aria-label="展开侧边栏分类 &#x27;Paddle 零基础深度学习（第二版）&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/动手学深度学习pytorch-版">动手学深度学习（Pytorch 版）</a><button aria-label="展开侧边栏分类 &#x27;动手学深度学习（Pytorch 版）&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Notes/docs/intro">学而时习之</a></li></ul></nav></div></div></aside><main class="docMainContainer_dhcR"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_hWfg"><div class="docItemContainer_UIwD"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_ViMa" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/Notes/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_xAfz"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/Notes/docs/category/机器学习初步周志华"><span itemprop="name">机器学习初步（周志华）</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Task02</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_xgD3 theme-doc-toc-mobile tocMobile_UvqM"><button type="button" class="clean-btn tocCollapsibleButton_ldZF">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>Task02</h1></header><h3 class="anchor anchorWithStickyNavbar_QJwc" id="20-模型评估与选择概念树">2.0 模型评估与选择—概念树<a href="#20-模型评估与选择概念树" class="hash-link" aria-label="2.0 模型评估与选择—概念树的直接链接" title="2.0 模型评估与选择—概念树的直接链接">​</a></h3>
<p>Date：2022/10/18</p>
<hr>
<p>[TOC]</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="21-泛化能力">2.1 泛化能力<a href="#21-泛化能力" class="hash-link" aria-label="2.1 泛化能力的直接链接" title="2.1 泛化能力的直接链接">​</a></h3>
<ul>
<li>什么是好模型？</li>
<li>学科深入后，会发现其看待问题有一个独特的角度。
<ul>
<li>搞清楚你要什么，才知道我要给你什么</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018154816068" src="/Notes/assets/images/image-20221018154816068-5e7dad438be4c30f089f61851413ddbb.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>generalization ability</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018160402041" src="/Notes/assets/images/image-20221018160402041-da07995caa9ae41f7ff2d24bc73c03a1.png" width="803" height="361" class="img_O9Fa"></p>
<ul>
<li>这题之前，课程并无解释上述概念，于是出现一些非线性的认知尝试，例如跳出去列概念表、翻阅书中相应内容以看定义等操作。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018160256738" src="/Notes/assets/images/image-20221018160256738-fce6a43dbef42f2fb1a6eb97c06ed299.png" width="789" height="399" class="img_O9Fa"></p>
<ul>
<li>拟合与泛化能力，看似非常相似——但我理解的拟合是对学习过程的训练样本而言的，乍一看不清晰，但仔细思考比对后才见真相。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018160543398" src="/Notes/assets/images/image-20221018160543398-cfaabbdf3b8d02adeb0cedc82cd708ce.png" width="796" height="176" class="img_O9Fa"></p>
<ul>
<li>模型的意义在于对未知数据的处理能力。</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="22-过拟合和欠拟合">2.2 过拟合和欠拟合<a href="#22-过拟合和欠拟合" class="hash-link" aria-label="2.2 过拟合和欠拟合的直接链接" title="2.2 过拟合和欠拟合的直接链接">​</a></h3>
<p><img decoding="async" loading="lazy" alt="image-20221018161219881" src="/Notes/assets/images/image-20221018161219881-a7063abdd83d65b08653b1cd1c568508.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>能控制的是训练集上的结果，但我们想要的是未来的结果，因此，一定要在两者之间找到某种联系，如果不存在联系，那么 ML 学科就不必存在了（即给你的东西与未来完全不发生关系），而我们的假设是，给定的数据与未来的数据都符合某种规律。
<ul>
<li>如何确定我们真正把这个规律发掘出来了？</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018161409767" src="/Notes/assets/images/image-20221018161409767-c5f529e37decd7c5275e8815601bdc76.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>把不该学的东西学到了——过拟合。</li>
<li>欠拟合——没有训练之前也算是欠配，通常是没有把必要的特征学到，该学的没有学。</li>
<li>U 型曲线
<ul>
<li><strong>过拟合是 ML 的核心内容——所有的技术都可认为在缓解过拟合（根本问题）</strong>
<ul>
<li><strong>这个算法靠什么缓解过拟合？</strong></li>
<li><strong>这个缓解策略什么情况会失效？</strong></li>
</ul>
</li>
<li>基于 P ≠ NP，因此无法得到最优模型</li>
</ul>
</li>
<li>【这一段对人的学习也具有启发性】</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="23-三大问题">2.3 三大问题<a href="#23-三大问题" class="hash-link" aria-label="2.3 三大问题的直接链接" title="2.3 三大问题的直接链接">​</a></h3>
<p><img decoding="async" loading="lazy" alt="image-20221018170447789" src="/Notes/assets/images/image-20221018170447789-758b315c693fbd282e32ed833d6328c2.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>
<p>对于未来的数据，要设计评估的方法——如果一个模型总是对的，但对于交易诈骗这种百万分之一的情况，这个模型准确率也有99%，但明显不是我们想要的模型。</p>
</li>
<li>
<p>理解以前/现在有什么刻画的标准，才有可能对未来进行创新</p>
</li>
<li>
<p>统计意义上的好模型——比较检验</p>
</li>
<li>
<p>上述列举的，只是有什么，而不是所有的情况——以后工作可能需要根据任务新发明、新设计出度量。</p>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018170701692" src="/Notes/assets/images/image-20221018170701692-c2a7b9ac11b5112b0bff69de8305ed94.png" width="790" height="360" class="img_O9Fa"></p>
<ul>
<li>==【WRONG】如何理解统计意义上表现好？其他几种是用来做什么的？我错误的原因主要是没有缕清三者的定义、定位、作用。==</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018170804159" src="/Notes/assets/images/image-20221018170804159-b69d2666f15bcc1b615e773d1136aec2.png" width="806" height="183" class="img_O9Fa"></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="24-评估方法">2.4 评估方法<a href="#24-评估方法" class="hash-link" aria-label="2.4 评估方法的直接链接" title="2.4 评估方法的直接链接">​</a></h3>
<p><img decoding="async" loading="lazy" alt="image-20221018171233618" src="/Notes/assets/images/image-20221018171233618-e0ced7cf70b8293dac838783e181181f.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>发明一种方法还是很困难的，所以要先搞清楚常用的有什么。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018171742983" src="/Notes/assets/images/image-20221018171742983-b501b860e6e64371ec78959a11cd675c.png" width="1920" height="1079" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018171632352" src="/Notes/assets/images/image-20221018171632352-651b0c29b59e1d2bce23b2f5c815f0ff.png" width="1007" height="660" class="img_O9Fa"></p>
<ul>
<li>如何划分很重要，引出一个不可调和的矛盾</li>
<li>最后要把所有数据合起来，重新训练一遍再给用户【未理解】</li>
<li>局限：可能总是存在一些没有使用过的数据（例如考试知识点，每次随机几个，但总有两个知识点没抽到过，导致性能在那两个知识点上一塌糊涂）</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018172359583" src="/Notes/assets/images/image-20221018172359583-bd9d5bf48292a2732af1f3507fcf05c7.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>为了更好地使用训练样本，以达到更好的逼近，即解决 hold-out 法的不足</li>
<li>每一个环节都是 NFL</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mn>99</mn></msub><mo>→</mo><msub><mi>M</mi><mrow><mi>M</mi><mn>100</mn></mrow></msub></mrow><annotation encoding="application/x-tex">M_{99} \rightarrow M_{M100}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">99</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span><span class="mord mtight">100</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 不一定比前面 80 个或 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><mo>×</mo><mn>10</mn><mi>C</mi><mi>V</mi></mrow><annotation encoding="application/x-tex">10 \times 10  CV</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">10</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">10</span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span> 更准确，因为 NFL</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018172923992" src="/Notes/assets/images/image-20221018172923992-1103979639db9e8522ea0417416476a8.png" width="1920" height="1079" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018172706163" src="/Notes/assets/images/image-20221018172706163-e188f1d446aecd8bfe71bd636a40e84d.png" width="1070" height="822" class="img_O9Fa"></p>
<ul>
<li>数据太少的时候很有用</li>
<li>但会改变数据的分布，用后一种分布去近似了，但如果认为分布的改变可以忽略，那么就很有用</li>
<li>以后，在集成学习方法当中，这是一种关键技术</li>
<li>虽然 “重复采样” 看上去简单，但在统计学有非常深刻的东西，统计大师 Efron 专门写过一本书 Bootstrap</li>
<li>概括：bootstrap sampling改变样本分布，适用对样本分布不敏感，样本量小的情况</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018174221923" src="/Notes/assets/images/image-20221018174221923-18c95bfb0a880d020cda0a828343b43a.png" width="811" height="360" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018174310339" src="/Notes/assets/images/image-20221018174310339-b046dcbcffcde7a330c776771bdbfa7a.png" width="814" height="373" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018174424653" src="/Notes/assets/images/image-20221018174424653-3940704d6efbeb37c54323f89bcb2560.png" width="756" height="133" class="img_O9Fa"></p>
<ul>
<li>==【WRONG】==</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018174452237" src="/Notes/assets/images/image-20221018174452237-b517b8f7f5dd6aa902f67292e8e81f02.png" width="801" height="168" class="img_O9Fa"></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="25-调参与验证集">2.5 调参与验证集<a href="#25-调参与验证集" class="hash-link" aria-label="2.5 调参与验证集的直接链接" title="2.5 调参与验证集的直接链接">​</a></h3>
<p><img decoding="async" loading="lazy" alt="image-20221018174838079" src="/Notes/assets/images/image-20221018174838079-b7c3fe6169bafe5beac0187c460a08ac.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>模型选择是一个很广泛的概念，例如算法的选择也可以看作是一个变量，实际上模型选择囊括了这一个过程中所有的变量可能性。每次的调整、每一轮的训练，其实都得到了一个新的模型。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018175033267" src="/Notes/assets/images/image-20221018175033267-3922403c1fcaac883a6205a6205b02b7.png" width="791" height="367" class="img_O9Fa"></p>
<ul>
<li>调参是训练过程的一部分，因此绝不能在测试集当中进行（新手往往的错误）</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018175130876" src="/Notes/assets/images/image-20221018175130876-6b25bb5b18a793232c5d6a608f5cc959.png" width="815" height="379" class="img_O9Fa"></p>
<ul>
<li>超参数，即人工设定的内容，算法的参数；区别计算机的任务，即模型的参数——这其中能够看到人机的分工与协同工作。</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="26-性能度量">2.6 性能度量<a href="#26-性能度量" class="hash-link" aria-label="2.6 性能度量的直接链接" title="2.6 性能度量的直接链接">​</a></h3>
<p><img decoding="async" loading="lazy" alt="image-20221018180025475" src="/Notes/assets/images/image-20221018180025475-d67fddc6879b89190ae117fee27ecb2c.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>一个算法，对A好，不一定对B好，因为它们想的可能不是同一个目标。【突然想起迁移学习，例如神经网络的靠近输入层和靠近输出层的抽象意义不同，靠近输入层的那些内容，通常可以推广到类似的任务，以此为基础再针对性地设计靠近输出层的网络】</li>
<li>同称为二次误差、平方误差</li>
<li>有时候系数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> ，对结果没有影响，因为所有模型、所有选择都乘以这个系数了——但这样操作可以带来一个计算上的好处：把导数产生的 2 消去了。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018180208365" src="/Notes/assets/images/image-20221018180208365-a81cd14aa395ef2765a8d2af21fcd77b.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>这些指标太简单，因此通常会使用一个混淆矩阵</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018180528527" src="/Notes/assets/images/image-20221018180528527-31983e33112a5501c53c4f6f15d8b2de.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>precision 有些地方翻译为精度，但为了避免跟上门的 accuracy 混淆，此处翻译为查准率</li>
<li>这样描述，对模型的精度就有了一个更具体的刻画了</li>
<li>但由于 P 和 R 有时候人的角度看不过来，有时候 P 上更好，有时候 R 上更好，那到底谁好？于是我们把两者合在一起</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018180810065" src="/Notes/assets/images/image-20221018180810065-f20ac7473d45b7b16fa3becb1cf2a30a.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li><strong>使用调和平均，使得两数差异可以体现，较小值不会被忽视</strong>——反之，如果使用算术平均，那 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>a</mi><mo>+</mo><mi>b</mi></mrow><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{a + b}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2251em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 中 a 与 b 差异无法体现。</li>
<li>有时候以为要死记硬背，但只要知道从右边公式来的——<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span> 相当于引入一个权重，那么就更清晰了，由此可以对查准率与查全率针对性地偏好。
<ul>
<li>其实就是右侧公式的两个分子进行比较</li>
<li>加权调和平均</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018181432946" src="/Notes/assets/images/image-20221018181432946-843369f406e9bd0d1048d6faac424fa0.png" width="801" height="364" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018181603969" src="/Notes/assets/images/image-20221018181603969-dd9faa14e1cd18f1be1c9e2fbe9633eb.png" width="818" height="393" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018181640245" src="/Notes/assets/images/image-20221018181640245-2f1f66df2d9fb969d652a48308ea7983.png" width="808" height="220" class="img_O9Fa"></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="27-比较检验">2.7 比较检验<a href="#27-比较检验" class="hash-link" aria-label="2.7 比较检验的直接链接" title="2.7 比较检验的直接链接">​</a></h3>
<ul>
<li>背景：0.88 VS 0.9 是不是 0.9 一定更好？==【前面的几个环节，也要梳理出这个需求】==
<ul>
<li>不能。因为是复杂综合的结果，并<strong>不能单一维度去比较</strong>【想起糖尿病遗传风险比赛，当时我就怀疑仅仅比较准确率，或者模型仅生成了这样一个指标，是否有说服力的问题——在这里可以找到答案。不过比赛具有特殊性】【多维度思考的角度】</li>
<li>并且，<strong>我们不是在找确定的最优，而是概率的近似正确</strong>。</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018182204809" src="/Notes/assets/images/image-20221018182204809-8b4a35ed8ae1461ca9e35c53c693ab31.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>==03:00 左右，讲到学习的态度、程度问题，非常重要== 【待总结】</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018182819299" src="/Notes/assets/images/image-20221018182819299-71e314cdd131bb3e051b358fbf53c177.png" width="1920" height="1079" class="img_O9Fa"></p>
<ul>
<li>需借助数理统计 “假设检验” 的方法
<ul>
<li>这些假设检验，不必死记硬背，目前很多工具包里都有，调用即可</li>
<li>==更重要的是，知道什么时候该用什么，以及为什么==</li>
<li>具体检验如何进行，自己翻书</li>
</ul>
</li>
<li>McNemar 检验
<ul>
<li>是列联表后，考虑反对角线上的两个点</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018182635548" src="/Notes/assets/images/image-20221018182635548-a92a031724a7794d2b75d2948f80b834.png" width="995" height="581" class="img_O9Fa"></p>
<ul>
<li>数理统计中，标准的 t 检验、成对的 t 检验
<ul>
<li>零均值，浮动；由此可以用得到的均值、标准差来判断是否属于这个分布（零均值、浮动的分布）</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018190717564" src="/Notes/assets/images/image-20221018190717564-fa6428a6d2845d641024add66a84afc1.png" width="827" height="380" class="img_O9Fa"></p>
<ul>
<li>什么是列联表？（P41）</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018191310124" src="/Notes/assets/images/image-20221018191310124-3635ed0441c4935f46ca23b91138ba26.png" width="810" height="349" class="img_O9Fa"></p>
<ul>
<li>什么是统计显著性？t检验是什么？</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018191434114" src="/Notes/assets/images/image-20221018191434114-276188805a9fa6c0d4235fad2428fe3d.png" width="812" height="172" class="img_O9Fa"></p>
<ul>
<li>
<p>==【疑惑】==</p>
<ul>
<li>为什么学完这个视频，==基本上不理解甚至没有吸收到上述两个学习器的概念？==</li>
<li>这个认知上的忽视过程，<strong>源于缺乏相关统计知识</strong>支撑；</li>
<li>重新看一遍视频，判断一下忽略了什么，什么不理解，为什么不理解。</li>
<li>最小二乘法</li>
</ul>
</li>
<li>
<p>【感悟】</p>
<ul>
<li>需补充数理统计知识</li>
<li>需分步分析划分训练集的几种方法，梳理算法步骤</li>
</ul>
</li>
<li>
<p>视频断层</p>
<ul>
<li>较多黑板内容剪辑掉了</li>
</ul>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="02-exam">【02 EXAM】<a href="#02-exam" class="hash-link" aria-label="【02 EXAM】的直接链接" title="【02 EXAM】的直接链接">​</a></h3>
<p><img decoding="async" loading="lazy" alt="image-20221018192751747" src="/Notes/assets/images/image-20221018192751747-618e3df0a893d3c98458478510490ce1.png" width="797" height="388" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018193036453" src="/Notes/assets/images/image-20221018193036453-74ff68880a758bcda10b905f640bf5a4.png" width="794" height="404" class="img_O9Fa"></p>
<ul>
<li>为什么需要重新训练模型？对应本章的什么内容？</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018193257297" src="/Notes/assets/images/image-20221018193257297-b47f91d7bbc47fa09bb1b15c1d95c80f.png" width="789" height="382" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018193349659" src="/Notes/assets/images/image-20221018193349659-535c11382c9adccd639f32bff5072db8.png" width="796" height="390" class="img_O9Fa"></p>
<ul>
<li>可逐条理解
<ul>
<li>A 测试性能只是一种基于已知样本，对未知样本的近似估计；而泛化性能对未知；</li>
<li>B 测试集不同，数据差异会带来扰动</li>
<li>C 例如神经网络，初始化条件不同，结果也不同</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018193331910" src="/Notes/assets/images/image-20221018193331910-6ddf4443f3cd5318c9dbac61fc764e6c.png" width="801" height="164" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018194728694" src="/Notes/assets/images/image-20221018194728694-0bec863576032def36b07093f9e2c658.png" width="800" height="183" class="img_O9Fa"></p>
<ul>
<li>本来很怀疑，结果对了——怀疑的原因是：均方误差的取值范围——但仔细回忆，发现跟概率分布取值范围 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span> 混淆了</li>
<li>而且也说不清最小二乘法——但公式用对了。为什么叫最小二乘法？谁提出的？</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018194754460" src="/Notes/assets/images/image-20221018194754460-838944e4d64163b07f57a62298853751.png" width="807" height="163" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018195037683" src="/Notes/assets/images/image-20221018195037683-0956bc5b6080875d94af0261bec9a7f1.png" width="801" height="179" class="img_O9Fa"></p>
<ul>
<li>什么时候才可以推给用户？需满足什么条件？
<ul>
<li>课上讲过类似的，比如数据集合在一起重新训练一遍后，再推。书上则强调需随机多次划分、重复进行实验评估，最后取平均值。——或许退给用户的时候，就是这个平均值结果较好的时候，取决于具体需求。</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018195618823" src="/Notes/assets/images/image-20221018195618823-3b9e19565f40007965000645a792d598.png" width="793" height="190" class="img_O9Fa"></p>
<ul>
<li>==【WRONG】并不理解这题，尤其是背后的原理==</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018195750994" src="/Notes/assets/images/image-20221018195750994-e53bda1648efeedc2e8293b6aeda0c89.png" width="804" height="183" class="img_O9Fa"></p>
<ul>
<li>按照 P27 的讲述，训练模型与使用整个数据集训练的模型应该是很相似的。【但我还未理解这种相似性的来源——即 “只少了一个样本” 这句话，同时未理解的也包括前文 M80、M99、M100】</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018200319297" src="/Notes/assets/images/image-20221018200319297-bbd3915df330c83dd385fb26b188f2cf.png" width="798" height="305" class="img_O9Fa"></p>
<ul>
<li>==【WRONG】混淆了 TN 与 FN==</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018200433849" src="/Notes/assets/images/image-20221018200433849-7829f833574056b09d50549a0f4ef6ec.png" width="726" height="169" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018200423056" src="/Notes/assets/images/image-20221018200423056-a1c738694104d242494edb64150dc221.png" width="737" height="107" class="img_O9Fa"></p>
<ul>
<li>为什么会混淆？而且套公式的时候有一种焦虑感——因为套公式的行为。</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018200806903" src="/Notes/assets/images/image-20221018200806903-1554893f7972bc5cd011b74eab257721.png" width="806" height="418" class="img_O9Fa"></p>
<ul>
<li>==【WRONG】总是做错的题目，判断完全相反了。==
<ul>
<li>做这题的时候，我==完全没想起两者对应的公式==</li>
<li>我的理解是，用大于 0.5 的阈值，判断为 1 的分类少了，0 的分类多了。</li>
<li>由此，假设一开始好瓜都挑出来了，那么这个调整会减少一些 FP，即提高了查准率；假设一开始只挑出了部分好瓜，这个调整会减少一些 FP 的可能性，同时也把更多的好瓜过滤掉了——查准率同样会提高。
<ul>
<li>不过问题在于，同时增加、同时减少，带来的整体变化是如何？或许要证明一个不等式。又或者有更加简便的理解方式。</li>
<li><strong>应根据两对角线理解混淆矩阵</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221018201201331" src="/Notes/assets/images/image-20221018201201331-728d17bd311a217111719055d7b6679c.png" width="674" height="155" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20221018202340266" src="/Notes/assets/images/image-20221018202340266-fddfa422e1518b2ba189926993562033.png" width="808" height="374" class="img_O9Fa"></p>
<ul>
<li>这题同样懵逼——因为缺少（至少没有系统学过）数理统计的知识。（P26 上）
<ul>
<li>但吴恩达有讲过类似的，过了几个月，不记得了</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20221019234813342" src="/Notes/assets/images/image-20221019234813342-3d749aae20b346482e241f7d2e0f2ac4.png" width="712" height="231" class="img_O9Fa"></p>
<p>2022/10/18 20:38:39 44min + 1h27min + 1h34min = 225min = 3.75h</p>
<hr></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/Notes/docs/machine_learning/Task01"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">Task01</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Notes/docs/machine_learning/Task03"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">Task03</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_G4nv thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#20-模型评估与选择概念树" class="table-of-contents__link toc-highlight">2.0 模型评估与选择—概念树</a></li><li><a href="#21-泛化能力" class="table-of-contents__link toc-highlight">2.1 泛化能力</a></li><li><a href="#22-过拟合和欠拟合" class="table-of-contents__link toc-highlight">2.2 过拟合和欠拟合</a></li><li><a href="#23-三大问题" class="table-of-contents__link toc-highlight">2.3 三大问题</a></li><li><a href="#24-评估方法" class="table-of-contents__link toc-highlight">2.4 评估方法</a></li><li><a href="#25-调参与验证集" class="table-of-contents__link toc-highlight">2.5 调参与验证集</a></li><li><a href="#26-性能度量" class="table-of-contents__link toc-highlight">2.6 性能度量</a></li><li><a href="#27-比较检验" class="table-of-contents__link toc-highlight">2.7 比较检验</a></li><li><a href="#02-exam" class="table-of-contents__link toc-highlight">【02 EXAM】</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>