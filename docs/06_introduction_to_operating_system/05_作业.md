### C03

* 作业：
* 书中问题：



------



### C04

* 作业：
  * （模拟）模拟作业以模拟器的形式出现，你运行它以确保理解某些内容。模拟器通常是Python程序，它们让你能够生成不同的问题（使用不同的随机种子），也让程序为你解决问题（带-c标志），以便你检查答案。使用-h或--help标志运行任何模拟器，将提供有关模拟器所有选项的更多信息。每个模拟器附带的README文件提供了有关如何运行它的更多详细信息，其中详细描述了每个标志。
  * 程序process-run.py让你查看程序运行时进程状态如何改变，是在使用CPU（例如，执行相加指令）还是执行I/O（例如，向磁盘发送请求并等待它完成）。详情请参阅README文件。
* 书中问题：
  * 1．用以下标志运行程序：./process-run.py -l 5:100,5:100。CPU利用率（CPU使用时间的百分比）应该是多少？为什么你知道这一点？利用 -c标记查看你的答案是否正确。
  * 2．现在用这些标志运行：./process-run.py -l 4:100,1:0。这些标志指定了一个包含4条指令的进程（都要使用CPU），并且只是简单地发出I/O并等待它完成。完成这两个进程需要多长时间？利用-c检查你的答案是否正确。
  * 3．现在交换进程的顺序：./process-run.py -l 1:0,4:100。现在发生了什么？交换顺序是否重要？为什么？同样，用-c看看你的答案是否正确。
  * 4．现在探索另一些标志。一个重要的标志是-S，它决定了当进程发出I/O时系统如何反应。将标志设置为SWITCH_ON_END，在进程进行I/O操作时，系统将不会切换到另一个进程，而是等待进程完成。当你运行以下两个进程时，会发生什么情况？一个执行I/O，另一个执行CPU工作。（-l 1:0,4:100 -c -S SWITCH_ON_END）
  * 5．现在，运行相同的进程，但切换行为设置，在等待I/O时切换到另一个进程（-l 1:0,4:100 -c -S SWITCH_ON_IO）。现在会发生什么？利用-c来确认你的答案是否正确。
  * 6．另一个重要的行为是I/O完成时要做什么。利用-I IO_RUN_LATER，当I/O完成时，发出它的进程不一定马上运行。相反，当时运行的进程一直运行。当你运行这个进程组合时会发生什么？（./process-run.py -l 3:0,5:100,5:100,5:100 -S SWITCH_ON_IO -I IO_RUN_LATER -c -p）系统资源是否被有效利用？
  * 7．现在运行相同的进程，但使用-I IO_RUN_IMMEDIATE设置，该设置立即运行发出I/O的进程。这种行为有何不同？为什么运行一个刚刚完成I/O的进程会是一个好主意？
  * 8．现在运行一些随机生成的进程，例如-s 1 -l 3:50,3:50, -s 2 -l 3:50,3:50, -s 3 -l 3:50,3:50。看看你是否能预测追踪记录会如何变化？当你使用-I IO_RUN_IMMEDIATE与-I IO_RUN_LATER时会发生什么？当你使用-S SWITCH_ON_IO与-S SWITCH_ON_END时会发生什么？



------



### C05

* 作业：（编码）在这个作业中，你要熟悉一下刚读过的进程管理API。别担心，它比听起来更有趣！如果你找到尽可能多的时间来编写代码，通常会增加成功的概率[5]，为什么不现在就开始呢？
* 书中问题：
  * 1．编写一个调用fork()的程序。在调用fork()之前，让主进程访问一个变量（例如x）并将其值设置为某个值（例如100）。子进程中的变量有什么值？当子进程和父进程都改变x的值时，变量会发生什么？
  * 2．编写一个打开文件的程序（使用open()系统调用），然后调用fork()创建一个新进程。子进程和父进程都可以访问open()返回的文件描述符吗？当它们并发（即同时）写入文件时，会发生什么？
  * 3．使用fork()编写另一个程序。子进程应打印“hello”，父进程应打印“goodbye”。你应该尝试确保子进程始终先打印。你能否不在父进程调用wait()而做到这一点呢？
  * 4．编写一个调用fork()的程序，然后调用某种形式的exec()来运行程序/bin/ls。看看是否可以尝试exec()的所有变体，包括execl()、execle()、execlp()、execv()、execvp()和execvP()。为什么同样的基本调用会有这么多变种？
  * 5．现在编写一个程序，在父进程中使用wait()，等待子进程完成。wait()返回什么？如果你在子进程中使用wait()会发生什么？
  * 6．对前一个程序稍作修改，这次使用waitpid()而不是wait()。什么时候waitpid()会有用？
  * 7．编写一个创建子进程的程序，然后在子进程中关闭标准输出（STDOUT_FILENO）。如果子进程在关闭描述符后调用printf()打印输出，会发生什么？
  * 8．编写一个程序，创建两个子进程，并使用pipe()系统调用，将一个子进程的标准输出连接到另一个子进程的标准输入。



------



### C06

* 作业：（测量）测量作业是小型练习。你可以编写代码在真实机器上运行，从而测量操作系统或硬件性能的某些方面。这样的作业背后的想法是给你一点实际操作系统的实践经验。



------



### C07

* 作业：scheduler.py这个程序允许你查看不同调度程序在调度指标（如响应时间、周转时间和总等待时间）下的执行情况。详情请参阅README文件。

* 书中问题：
  * 1．使用SJF和FIFO调度程序运行长度为200的3个作业时，计算响应时间和周转时间。
  * 2．现在做同样的事情，但有不同长度的作业，即100、200和300。
  * 3．现在做同样的事情，但采用RR调度程序，时间片为1。
  * 4．对于什么类型的工作负载，SJF提供与FIFO相同的周转时间？
  * 5．对于什么类型的工作负载和量子长度，SJF与RR提供相同的响应时间？
  * 6．随着工作长度的增加，SJF的响应时间会怎样？你能使用模拟程序来展示趋势吗？
  * 7．随着量子长度的增加，RR的响应时间会怎样？你能写出一个方程，计算给定N个工作时，最坏情况的响应时间吗？

------



### C08

* 作业：程序mlfq.py允许你查看本章介绍的MLFQ调度程序的行为。详情请参阅README文件。
* 书中问题：
  * 1．只用两个工作和两个队列运行几个随机生成的问题。针对每个工作计算MLFQ的执行记录。限制每项作业的长度并关闭I/O，让你的生活更轻松。
  * 2．如何运行调度程序来重现本章中的每个实例？
  * 3．将如何配置调度程序参数，像轮转调度程序那样工作？
  * 4．设计两个工作的负载和调度程序参数，以便一个工作利用较早的规则4a和4b（用-S标志打开）来“愚弄”调度程序，在特定的时间间隔内获得99%的CPU。
  * 5．给定一个系统，其最高队列中的时间片长度为10ms，你需要如何频繁地将工作推回到最高优先级级别（带有-B标志），以保证一个长时间运行（并可能饥饿）的工作得到至少5%的CPU？
  * 6．调度中有一个问题，即刚完成I/O的作业添加在队列的哪一端。-I标志改变了这个调度模拟器的这方面行为。尝试一些工作负载，看看你是否能看到这个标志的效果。



------



### C09

* 作业：lottery.py这个程序允许你查看彩票调度程序的工作原理。详情请参阅README文件。
* 书中问题：
  
  * 1．计算3个工作在随机种子为1、2和3时的模拟解。
  
  * 2．现在运行两个具体的工作：每个长度为10，但是一个（工作0）只有一张彩票，另一个（工作1）有100张（−l 10∶1,10∶100）。
  
    彩票数量如此不平衡时会发生什么？在工作1完成之前，工作0是否会运行？多久？一般来说，这种彩票不平衡对彩票调度的行为有什么影响？
  
  * 3．如果运行两个长度为100的工作，都有100张彩票（−l100∶100,100∶100），调度程序有多不公平？运行一些不同的随机种子来确定（概率上的）答案。不公平性取决于一项工作比另一项工作早完成多少。
  
  * 4．随着量子规模（-q）变大，你对上一个问题的答案如何改变？
  
  * 5．你可以制作类似本章中的图表吗
  
    还有什么值得探讨的？用步长调度程序，图表看起来如何？



------



### C10

* 作业：
* 书中问题：
  * 



------



### C11

* 作业：
* 书中问题：
  * 



------



### C12

* 作业：
* 书中问题：
  * 



------



### C13

* 作业：
* 书中问题：
  * 



------



### C14

* 作业：
  * （编码）在这个作业中，你会对内存分配有所了解。首先，你会写一些错误的程序（好玩！）。然后，利用一些工具来帮助你找到其中的错误。最后，你会意识到这些工具有多棒，并在将来使用它们，从而使你更加快乐和高效。
  * 你要使用的第一个工具是调试器gdb。关于这个调试器有很多需要了解的知识，在这里，我们只是浅尝辄止。
  * 你要使用的第二个工具是valgrind [SN05]。该工具可以帮助查找程序中的内存泄露和其他隐藏的内存问题。如果你的系统上没有安装，请访问valgrind网站并安装它。
* 书中问题：
  * 1．编写一个名为null.c的简单程序，它创建一个指向整数的指针，将其设置为NULL，然后尝试对其进行释放内存操作。把它编译成一个名为null的可执行文件。当你运行这个程序时会发生什么？
  * 2．编译该程序，其中包含符号信息（使用-g 标志）。这样做可以将更多信息放入可执行文件中，使调试器可以访问有关变量名称等的更多有用信息。通过输入gdb null，在调试器下运行该程序，然后，一旦gdb运行，输入run。gdb显示什么信息？
  * 3．对这个程序使用valgrind工具。我们将使用属于valgrind的memcheck工具来分析发生的情况。输入以下命令来运行程序：valgrind --leak-check=yes null。当你运行它时会发生什么？你能解释工具的输出吗？
  * 4．编写一个使用malloc()来分配内存的简单程序，但在退出之前忘记释放它。这个程序运行时会发生什么？你可以用gdb来查找它的任何问题吗？用valgrind呢（再次使用--leak-check=yes标志）？
  * 5．编写一个程序，使用malloc()创建一个名为data、大小为100的整数数组。然后，将data[100]设置为0。当你运行这个程序时会发生什么？当你使用valgrind运行这个程序时会发生什么？程序是否正确？
  * 6．创建一个分配整数数组的程序（如上所述），释放它们，然后尝试打印数组中某个元素的值。程序会运行吗？当你使用valgrind时会发生什么？
  * 7．现在传递一个有趣的值来释放（例如，在上面分配的数组中间的一个指针）。 会发生什么？你是否需要工具来找到这种类型的问题？
  * 8．尝试一些其他接口来分配内存。例如，创建一个简单的向量似的数据结构，以及使用realloc()来管理向量的相关函数。使用数组来存储向量元素。当用户在向量中添加条目时，请使用realloc()为其分配更多空间。这样的向量表现如何？它与链表相比如何？使用valgrind来帮助你发现错误。
  * 9．花更多时间阅读有关使用gdb和valgrind的信息。了解你的工具至关重要，花时间学习如何成为UNIX和C环境中的调试器专家。



------



### C15

* 作业：程序relocation.py让你看到，在带有基址和边界寄存器的系统中，如何执行地址转换。详情请参阅README文件。
* 书中问题：
  * 1．用种子1、2和3运行，并计算进程生成的每个虚拟地址是处于界限内还是界限外?如果在界限内，请计算地址转换。
  * 2．使用以下标志运行：-s 0 -n 10。为了确保所有生成的虚拟地址都处于边界内，要将-l（界限寄存器）设置为什么值？
  * 3．使用以下标志运行：-s 1 -n 10 -l 100。可以设置界限的最大值是多少，以便地址空间仍然完全放在物理内存中？
  * 4．运行和第3题相同的操作，但使用较大的地址空间（-a）和物理内存（-p）。
  * 5．作为边界寄存器的值的函数，随机生成的虚拟地址的哪一部分是有效的？画一个图，使用不同随机种子运行，限制值从0到最大地址空间大小。



------



### C16

* 作业：该程序允许你查看在具有分段的系统中如何执行地址转换。详情请参阅README文件。

* 书中问题：
  
  * 1．先让我们用一个小地址空间来转换一些地址。这里有一组简单的参数和几个不同的随机种子。你可以转换这些地址吗？
  
  ```bash
  segmentation.py -a 128 -p 512 -b 0 -l 20 -B 512 -L 20 -s 0
  segmentation.py -a 128 -p 512 -b 0 -l 20 -B 512 -L 20 -s 1
  segmentation.py -a 128 -p 512 -b 0 -l 20 -B 512 -L 20 -s 2
  ```
  
  * 2．现在，让我们看看是否理解了这个构建的小地址空间（使用上面问题的参数）。段0中最高的合法虚拟地址是什么？段1中最低的合法虚拟地址是什么？在整个地址空间中，最低和最高的非法地址是什么？最后，如何运行带有-A标志的segmentation.py来测试你是否正确？
  * 3．假设我们在一个128字节的物理内存中有一个很小的16字节地址空间。你会设置什么样的基址和界限，以便让模拟器为指定的地址流生成以下转换结果：有效，有效，违反……违反，有效，有效？假设用以下参数：
  
  ```bash
  segmentation.py -a 16 -p 128
    -A 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
    --b0 ? --l0 ? --b1 ? --l1 ?
  ```
  
  * 4．假设我们想要生成一个问题，其中大约90%的随机生成的虚拟地址是有效的（即不产生段异常）。你应该如何配置模拟器来做到这一点？哪些参数很重要？
  * 5．你可以运行模拟器，使所有虚拟地址无效吗？怎么做到？



------



### C17

* 作业：程序malloc.py让你探索本章中描述的简单空闲空间分配程序的行为。有关其基本操作的详细信息，请参见README文件。
* 书中问题：
  * 1．首先运行flag -n 10 -H 0 -p BEST -s 0来产生一些随机分配和释放。你能预测malloc()/free()会返回什么吗？你可以在每次请求后猜测空闲列表的状态吗？随着时间的推移，你对空闲列表有什么发现？
  * 2．使用最差匹配策略搜索空闲列表（-p WORST）时，结果有何不同？什么改变了？
  * 3．如果使用首次匹配（-p FIRST）会如何？使用首次匹配时，什么变快了？
  * 4．对于上述问题，列表在保持有序时，可能会影响某些策略找到空闲位置所需的时间。使用不同的空闲列表排序（-l ADDRSORT，-l SIZESORT +，-l SIZESORT-）查看策略和列表排序如何相互影响。
  * 5．合并空闲列表可能非常重要。增加随机分配的数量（比如说-n 1000）。随着时间的推移，大型分配请求会发生什么？在有和没有合并的情况下运行（即不用和采用-C标志）。你看到了什么结果差异？每种情况下的空闲列表有多大？在这种情况下，列表的排序是否重要？
  * 6．将已分配百分比-P改为高于50，会发生什么？它接近100时分配会怎样？接近0会怎样？
  * 7．要生成高度碎片化的空闲空间，你可以提出怎样的具体请求？使用-A标志创建碎片化的空闲列表，查看不同的策略和选项如何改变空闲列表的组织。



------



### C18

* 作业：在这个作业中，你将使用一个简单的程序（名为paging-linear-translate.py），来看看你是否理解了简单的虚拟—物理地址转换如何与线性页表一起工作。详情请参阅README文件。
* 书中问题：
  
  * 1．在做地址转换之前，让我们用模拟器来研究线性页表在给定不同参数的情况下如何改变大小。在不同参数变化时，计算线性页表的大小。一些建议输入如下，通过使用-v标志，你可以看到填充了多少个页表项。
  
    首先，要理解线性页表大小如何随着地址空间的增长而变化：
  
    ```bash
    paging-linear-translate.py -P 1k -a 1m -p 512m -v -n 0 
    paging-linear-translate.py -P 1k -a 2m -p 512m -v -n 0 
    paging-linear-translate.py -P 1k -a 4m -p 512m -v -n 0
    ```
  
    然后，理解线性页面大小如何随页大小的增长而变化：
  
    ```bash
    paging-linear-translate.py -P 1k -a 1m -p 512m -v -n 0 
    paging-linear-translate.py -P 2k -a 1m -p 512m -v -n 0 
    paging-linear-translate.py -P 4k -a 1m -p 512m -v -n 0
    ```
  
    在运行这些命令之前，请试着想想预期的趋势。页表大小如何随地址空间的增长而改变？随着页大小的增长呢？为什么一般来说，我们不应该使用很大的页呢？
  
  * 2．现在让我们做一些地址转换。从一些小例子开始，使用-u标志更改分配给地址空间的页数。例如：
  
    ```bash
    paging-linear-translate.py -P 1k -a 16k -p 32k -v -u 0 
    paging-linear-translate.py -P 1k -a 16k -p 32k -v -u 25 
    paging-linear-translate.py -P 1k -a 16k -p 32k -v -u 50 
    paging-linear-translate.py -P 1k -a 16k -p 32k -v -u 75 
    paging-linear-translate.py -P 1k -a 16k -p 32k -v -u 100
    ```
  
    如果增加每个地址空间中的页的百分比，会发生什么？
  
  * 3．现在让我们尝试一些不同的随机种子，以及一些不同的（有时相当疯狂的）地址空间参数：
  
    ```bash
    paging-linear-translate.py -P 8 -a 32  -p 1024 -v -s 1 
    paging-linear-translate.py -P 8k -a 32k -p 1m  -v -s 2 
    paging-linear-translate.py -P 1m -a 256m -p 512m -v -s 3
    ```
  
    哪些参数组合是不现实的？为什么？
  
  * 4．利用该程序尝试其他一些问题。你能找到让程序无法工作的限制吗？例如，如果地址空间大小大于物理内存，会发生什么情况？



------



### C19

* 作业：

本次作业要测算一下TLB的容量和访问TLB的开销。这个想法参考了Saavedra-Barrera的工作[SB92]，他用设计了一个简单而漂亮的用户级程序，来测算缓存层级结构的方方面面。更多细节请阅读他的论文。

基本原理就是访问一个跨多个内存页的大尺寸数据结构（例如数组），然后统计访问时间。例如，假设一个机器的TLB大小为4（这很小，但对这个讨论有用）。如果写一个程序访问4个或更少的页，每次访问都会命中TLB，因此相对较快。但是，如果在一个循环里反复访问5个或者更多的页，每次访问的开销就会突然跃升，因为发生TLB未命中。

循环遍历数组一次的基本代码应该像这样：

```cpp
int jump = PAGESIZE / sizeof(int);
for (i = 0; i < NUMPAGES * jump; i += jump) { 
    a[i] += 1;
}
```

在这个循环中，数组a中每页的一个整数被更新，直到NUMPAGES指定的页数。通过对这个循环反复执行计时（比如，在外层循环中执行几亿次这个循环，或者运行几秒钟所需的次数），就可以计算出平均每次访问所用的时间。随着NUMPAGES的增加，寻找开销的跃升，可以大致确定第一级TLB的大小，确定是否存在第二级TLB（如果存在，确定它的大小），总体上很好地理解TLB命中和未命中对于性能的影响。

图19.5　发现TLB大小和未命中开销：

![img](images/05_作业/epub_30179184_94.jfif)

从图19.5中可以看出，如果只访问少数页（8或更少），平均访问时间大约是5ns。如果访问16页或更多，每次访问时间突然跃升到20ns。最后一次开销跃升发生在1024页时，这时每次访问大约要70ns。通过这些数据，我们可以总结出这是一个二级的TLB，第一级较小（大约能存放8～16项），第二级较大，但较慢（大约能存放512项）。第一级TLB的命中和完全未命中的总体差距非常大，大约有14倍。TLB的性能很重要！

* 书中问题：
  * 1．为了计时，可能需要一个计时器，例如gettimeofday()提供的。这种计时器的精度如何？操作要花多少时间，才能让你对它精确计时？（这有助于确定需要循环多少次，反复访问内存页，才能对它成功计时。）
  * 2．写一个程序，命名为tlb.c，大体测算一下每个页的平均访问时间。程序的输入参数有：页的数目和尝试的次数。
  * 3．用你喜欢的脚本语言（csh、Python等）写一段脚本来运行这个程序，当访问页面从1增长到几千，也许每次迭代都乘2。在不同的机器上运行这段脚本，同时收集相应数据。需要试多少次才能获得可信的测量结果？
  * 4．接下来，将结果绘图，类似于上图。可以用ploticus这样的好工具画图。可视化使数据更容易理解，你认为是什么原因？
  * 5．要注意编译器优化带来的影响。编译器做各种聪明的事情，包括优化掉循环，如果循环中增加的变量后续没有使用。如何确保编译器不优化掉你写的TLB大小测算程序的主循环？
  * 6．还有一个需要注意的地方，今天的计算机系统大多有多个CPU，每个CPU当然有自己的TLB结构。为了得到准确的测量数据，我们需要只在一个CPU上运行程序，避免调度器把进程从一个CPU调度到另一个去运行。如何做到？（提示：在Google上搜索“pinning a thread”相关的信息）如果没有这样做，代码从一个CPU移到了另一个，会发生什么情况？
  * 7．另一个可能发生的问题与初始化有关。如果在访问数组a之前没有初始化，第一次访问将非常耗时，由于初始访问开销，比如要求置0。这会影响你的代码及其计时吗？如何抵消这些潜在的开销？



------



### C20

* 作业：这个有趣的小作业会测试你是否了解多级页表的工作原理。是的，前面句子中使用的“有趣”一词有一些争议。该程序叫作“可能不太怪：paging-multilevel-translate.py”。详情请参阅README文件。
* 书中问题：
  * 1．对于线性页表，你需要一个寄存器来定位页表，假设硬件在TLB未命中时进行查找。你需要多少个寄存器才能找到两级页表？三级页表呢？
  * 2．使用模拟器对随机种子0、1和2执行翻译，并使用-c标志检查你的答案。需要多少内存引用来执行每次查找？
  * 3．根据你对缓存内存的工作原理的理解，你认为对页表的内存引用如何在缓存中工作？它们是否会导致大量的缓存命中（并导致快速访问）或者很多未命中（并导致访问缓慢）？



------



### C21

* 作业：
* 书中问题：
  * 



------



### C22

* 作业：这个模拟器paging-policy.py允许你使用不同的页替换策略。详情请参阅README文件。
* 书中问题：
  * 1．使用以下参数生成随机地址：-s 0 -n 10，-s 1 -n 10和-s 2 -n 10。将策略从FIFO更改为LRU，并将其更改为OPT。计算所述地址追踪中的每个访问是否命中或未命中。
  * 2．对于大小为5的高速缓存，为以下每个策略生成最差情况的地址引用序列：FIFO、LRU和MRU（最差情况下的引用序列导致尽可能多的未命中）。对于最差情况下的引用序列，需要的缓存增大多少，才能大幅提高性能，并接近OPT？
  * 3．生成一个随机追踪序列（使用Python或Perl）。你预计不同的策略在这样的追踪序列上的表现如何？
  * 4．现在生成一些局部性追踪序列。如何能够产生这样的追踪序列？LRU表现如何？RAND比LRU好多少？CLOCK表现如何？CLOCK使用不同数量的时钟位，表现如何？
  * 5．使用像valgrind这样的程序来测试真实应用程序并生成虚拟页面引用序列。例如，运行valgrind --tool = lackey --trace-mem = yes ls将为程序ls所做的每个指令和数据引用，输出近乎完整的引用追踪。为了使上述仿真器有用，你必须首先将每个虚拟内存引用转换为虚拟页码参考（通过屏蔽偏移量并向右移位来完成）。为了满足大部分请求，你的应用程序追踪需要多大的缓存？随着缓存大小的增加绘制其工作集的图形。



------



### C23

* 作业：
* 书中问题：
  * 



------



### C24

* 作业：
* 书中问题：
  * 



------



