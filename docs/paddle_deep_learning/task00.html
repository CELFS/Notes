<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paddle_deep_learning/task00" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">task00 | 编程内外</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://CELFS.github.io/Notes/img/logo.png"><meta data-rh="true" name="twitter:image" content="https://CELFS.github.io/Notes/img/logo.png"><meta data-rh="true" property="og:url" content="https://CELFS.github.io/Notes/docs/paddle_deep_learning/task00"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="task00 | 编程内外"><meta data-rh="true" name="description" content="Task00 Paddle 深度学习总结"><meta data-rh="true" property="og:description" content="Task00 Paddle 深度学习总结"><link data-rh="true" rel="icon" href="/Notes/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://CELFS.github.io/Notes/docs/paddle_deep_learning/task00"><link data-rh="true" rel="alternate" href="https://CELFS.github.io/Notes/docs/paddle_deep_learning/task00" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://CELFS.github.io/Notes/docs/paddle_deep_learning/task00" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous"><link rel="stylesheet" href="/Notes/assets/css/styles.67339a6f.css">
<script src="/Notes/assets/js/runtime~main.793c07bf.js" defer="defer"></script>
<script src="/Notes/assets/js/main.ef11fa70.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/Notes/img/logo.png"><div role="region" aria-label="跳到主要内容"><a class="skipToContent__HuA" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Notes/"><div class="navbar__logo"><img src="/Notes/img/logo.png" alt="Notes Logo" class="themedComponent_Exct themedComponent--light_c3lc"><img src="/Notes/img/logo.png" alt="Notes Logo" class="themedComponent_Exct themedComponent--dark_Ji9V"></div><b class="navbar__title text--truncate">编程内外</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Notes/docs/category/linux-os">Notes</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/CELFS/Notes" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link" icon="github">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_OqSl"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_OAgU colorModeToggle_zRe0"><button class="clean-btn toggleButton_aClM toggleButtonDisabled_GkIb" type="button" disabled="" title="切换浅色/暗黑模式（当前为暗黑模式）" aria-label="切换浅色/暗黑模式（当前为暗黑模式）" aria-live="polite" aria-pressed="true"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_zzlY"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_Z832"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Cx4E"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_liLQ"><div class="docsWrapper_evXH"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_nZiY" type="button"></button><div class="docRoot_jKp6"><aside class="theme-doc-sidebar-container docSidebarContainer_wXyP"><div class="sidebarViewport_LQZ0"><div class="sidebar_T0dy"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_WBBB"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/linux-os">Linux OS</a><button aria-label="展开侧边栏分类 &#x27;Linux OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/ajax">Ajax</a><button aria-label="展开侧边栏分类 &#x27;Ajax&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/css">CSS</a><button aria-label="展开侧边栏分类 &#x27;CSS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/javascript-es6">JavaScript ES6</a><button aria-label="展开侧边栏分类 &#x27;JavaScript ES6&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/javascript">JavaScript</a><button aria-label="展开侧边栏分类 &#x27;JavaScript&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/nodejs">Node.js</a><button aria-label="展开侧边栏分类 &#x27;Node.js&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/typescript">TypeScript</a><button aria-label="展开侧边栏分类 &#x27;TypeScript&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/vue">Vue</a><button aria-label="展开侧边栏分类 &#x27;Vue&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/轻量级服务器开发tinywebserver">轻量级服务器开发（TinyWebServer）</a><button aria-label="展开侧边栏分类 &#x27;轻量级服务器开发（TinyWebServer）&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/c-后台服务器开发">C++ 后台服务器开发</a><button aria-label="展开侧边栏分类 &#x27;C++ 后台服务器开发&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/mysql-必知必会">MySQL 必知必会</a><button aria-label="展开侧边栏分类 &#x27;MySQL 必知必会&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/操作系统导论">操作系统导论</a><button aria-label="展开侧边栏分类 &#x27;操作系统导论&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/qt">QT</a><button aria-label="展开侧边栏分类 &#x27;QT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/读吴军信息论-40-讲">读吴军《信息论 40 讲》</a><button aria-label="展开侧边栏分类 &#x27;读吴军《信息论 40 讲》&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/读吴军富足">读吴军《富足》</a><button aria-label="展开侧边栏分类 &#x27;读吴军《富足》&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/machine-learning-andrew-ng">Machine Learning (Andrew Ng)</a><button aria-label="展开侧边栏分类 &#x27;Machine Learning (Andrew Ng)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/机器学习初步周志华">机器学习初步（周志华）</a><button aria-label="展开侧边栏分类 &#x27;机器学习初步（周志华）&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/Notes/docs/category/paddle-零基础深度学习第二版">Paddle 零基础深度学习（第二版）</a><button aria-label="折叠侧边栏分类 &#x27;Paddle 零基础深度学习（第二版）&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Notes/docs/paddle_deep_learning/task00">task00</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task01">task01</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task02">task02</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task03">task03</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task04">task04</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task05_01">task05_01</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task05_02">task05_02</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task06">task06</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task07">task07</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task08">task08</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task09">task09</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task10">task10</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task11">task11</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Notes/docs/paddle_deep_learning/task12">task12</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/Notes/docs/category/动手学深度学习pytorch-版">动手学深度学习（Pytorch 版）</a><button aria-label="展开侧边栏分类 &#x27;动手学深度学习（Pytorch 版）&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Notes/docs/intro">学而时习之</a></li></ul></nav></div></div></aside><main class="docMainContainer_dhcR"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_hWfg"><div class="docItemContainer_UIwD"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_ViMa" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/Notes/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_xAfz"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/Notes/docs/category/paddle-零基础深度学习第二版"><span itemprop="name">Paddle 零基础深度学习（第二版）</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">task00</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_xgD3 theme-doc-toc-mobile tocMobile_UvqM"><button type="button" class="clean-btn tocCollapsibleButton_ldZF">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>task00</h1></header><h3 class="anchor anchorWithStickyNavbar_QJwc" id="task00-paddle-深度学习总结">Task00 Paddle 深度学习总结<a href="#task00-paddle-深度学习总结" class="hash-link" aria-label="Task00 Paddle 深度学习总结的直接链接" title="Task00 Paddle 深度学习总结的直接链接">​</a></h3>
<p>Date：2023/03/15 17:13:08</p>
<hr>
<p>[TOC]</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="00-意义">00 意义<a href="#00-意义" class="hash-link" aria-label="00 意义的直接链接" title="00 意义的直接链接">​</a></h3>
<p>​		总结的意义在于，每当习得一系列的新知识，可以从一个符合自己认知习惯和规律的层面进行加工，从而帮助大脑形成合适的认知抽象视角，即可以帮助自己找准理解新知识的角度。我更愿意把这个目标称为 “获取合适的抽象视角” 。</p>
<ul>
<li>这样做的好处可以归纳为：
<ul>
<li>调动学习的<strong>主动性、参与感</strong>，对信息进行更深的<strong>加工</strong>，便于认知生理结构的形成；</li>
<li>提高<strong>信息提取</strong>的可能性；</li>
<li>形成<strong>信息快照</strong>，提高间隔性<strong>复盘效率</strong>；</li>
<li>帮助获取合适的抽象视角，便于找到对待新知的<strong>合适认知模式</strong>。</li>
</ul>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="01-深度学习简介">01 深度学习简介<a href="#01-深度学习简介" class="hash-link" aria-label="01 深度学习简介的直接链接" title="01 深度学习简介的直接链接">​</a></h3>
<ul>
<li>课程：<a href="https://aistudio.baidu.com/aistudio/education/group/info/25302" target="_blank" rel="noopener noreferrer">零基础实践深度学习（第 2 版）</a></li>
<li>部署：<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/install/conda/windows-conda.html#anchor-0" target="_blank" rel="noopener noreferrer">Windows 下 conda 部署 Paddle</a></li>
<li>延伸：<a href="https://www.paddlepaddle.org.cn/tutorials/projectdetail/5603475" target="_blank" rel="noopener noreferrer">进阶参考</a></li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="02-一个案例吃透深度学习">02 一个案例吃透深度学习<a href="#02-一个案例吃透深度学习" class="hash-link" aria-label="02 一个案例吃透深度学习的直接链接" title="02 一个案例吃透深度学习的直接链接">​</a></h3>
<p>​		本章以 “手写数字识别” 为例, 从横纵结合的视角分别展开讲述了深度学习任务流程的普遍共性，包括<strong>五个基本步骤</strong>：数据处理、模型设计、训练配置、训练过程、保存模型。</p>
<p><img decoding="async" loading="lazy" alt="img" src="/Notes/assets/images/29c753e301714502abc59e1d8318989f7a5ffdb75c11482da7df9225653ae42b-15c7e0a9b7234a1689bdd10f56236a65.png" width="1920" height="1058" class="img_O9Fa"></p>
<p>​		横纵讲述的方式，就像带着地图去学习，更有方向感，也能大致知道当前步骤存在的意义。不过，学了一遍之后，可能由于学得比较仓促，而且每个小节的项目文档还没有精读，导致第二天进行回顾的时候，并<strong>没有留下太深刻的整体印象，因此也难以掌握细枝末节</strong>，这个过程好比刷墙，目前只是简略地从上往下跳着涂了一遍，墙上还有许多留白的洞需要补上。因此，现针对昨日笔记，进行一次复盘小结。主要内容有：</p>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="01-背景知识">01 背景知识<a href="#01-背景知识" class="hash-link" aria-label="01 背景知识的直接链接" title="01 背景知识的直接链接">​</a></h4>
<ul>
<li>手写数字识别案例的意义</li>
<li>房价模型直接迁移带来的问题</li>
<li>横纵讲述的优点</li>
<li>baseline 的意义
<ul>
<li>关键：完整性</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="02-思路分析">02 思路分析<a href="#02-思路分析" class="hash-link" aria-label="02 思路分析的直接链接" title="02 思路分析的直接链接">​</a></h4>
<ul>
<li>数据处理的依赖包、基本思路</li>
<li>Paddle 的 API 文档
<ul>
<li>关键：理清输入、输出的数据类型</li>
<li><a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/index_cn.html" target="_blank" rel="noopener noreferrer">Paddle API 文档入口</a></li>
</ul>
</li>
<li>如何对房价模型进行调整，以适配手写识别任务
<ul>
<li>环节：模型设计、训练、测试</li>
<li>关键：判断原有的做法是否有效</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="03-数据处理">03 数据处理<a href="#03-数据处理" class="hash-link" aria-label="03 数据处理的直接链接" title="03 数据处理的直接链接">​</a></h4>
<ul>
<li>如何分析数据格式的显式特征</li>
<li>数据处理的五大操作（完整流程）
<ul>
<li>读入数据、拆分样本集合</li>
<li>训练样本集乱序、生成批次数据、校验数据有效性</li>
</ul>
</li>
<li>超参数与技巧较多，例如
<ul>
<li>学习用数据集（较理想） VS 开发用数据集（乱脏缺、需校验）</li>
<li>如何选择神经网络的层数、训练过程用什么方法</li>
<li>参数复杂度、训练步长、batch 凑齐……</li>
<li>关键之一：未污染的测试训练集</li>
</ul>
</li>
<li>模型性能的经验比较
<ul>
<li>从成果的角度：不明显的提升，通常意义不大</li>
<li>从技巧的角度：越精妙，往往越难迁移；越朴素，往往更具有通用意义</li>
</ul>
</li>
<li>异步读取数据（常用）
<ul>
<li>让两个环节脱钩, 并行来做, 整体会非常高效</li>
</ul>
</li>
<li>数据增广
<ul>
<li>局限性：任何数学技巧, 都不能弥补信息的缺失——Cornelius Lanczos</li>
<li>关键：合理伪造</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="04-网络结构">04 网络结构<a href="#04-网络结构" class="hash-link" aria-label="04 网络结构的直接链接" title="04 网络结构的直接链接">​</a></h4>
<ul>
<li>采用的神经网络不同，网络结构的将有所差异，所能解决的问题也会发生改变，这也是神经网络种类繁多的原因之一</li>
<li>类比视觉相关神经用来做听觉感知任务，效果是不如直接使用听觉相关神经来得好的，更何况输入的信号类型不一致，这也加大了迁移与学习的成本</li>
<li>关键：模型要有针对性, 匹配的才是好的</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="05-损失函数">05 损失函数<a href="#05-损失函数" class="hash-link" aria-label="05 损失函数的直接链接" title="05 损失函数的直接链接">​</a></h4>
<ul>
<li>分类任务
<ul>
<li>输出标签，由背后的概率分布支撑</li>
<li>损失函数：均方误差 VS 交叉熵
<ul>
<li>通常：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>交叉熵</mtext><mo>∼</mo><mfrac><mn>1</mn><mtext>准确率</mtext></mfrac></mrow><annotation encoding="application/x-tex">交叉熵 \sim \frac{1}{\text{准确率}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord cjk_fallback">交叉熵</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord cjk_fallback mtight">准确率</span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
</ul>
</li>
<li>激活函数：Softmax 函数（非线性变换）
<ul>
<li>Softmax 把模型的实际输出值变成概率分布值</li>
</ul>
</li>
<li>关键：最大似然思想（最小化交叉熵）</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="06-优化算法">06 优化算法<a href="#06-优化算法" class="hash-link" aria-label="06 优化算法的直接链接" title="06 优化算法的直接链接">​</a></h4>
<ul>
<li>学习率</li>
<li>四种主流优化算法：
<ul>
<li>SGD（随机）</li>
<li>Momentum（仿 “惯性”，减震）</li>
<li>AdaGrad（动态调整，渐降）</li>
<li>Adam（思路正交，二三结合，应用广泛）</li>
</ul>
</li>
<li>模型参数初始化
<ul>
<li>初始值：利用预训练模型的参数（可加速网络训练、得到较高精度）</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="07-资源配置">07 资源配置<a href="#07-资源配置" class="hash-link" aria-label="07 资源配置的直接链接" title="07 资源配置的直接链接">​</a></h4>
<ul>
<li>实际开发，往往需考虑 CPU、GPU 分布式训练（多卡）等资源调配问题</li>
<li>分布式训练（多卡）
<ul>
<li>模型并行：一个网络模型拆分多份，分到多个设备上（GPU）训练
<ul>
<li>张量并行、流水线并行</li>
<li>数据相同，节省内存，但应用受限</li>
</ul>
</li>
<li>数据并行：一次读取多份数据，给到多个设备（GPU）上的模型
<ul>
<li>CPU-PRC 稀疏参数、GPU-NCCL2 稠密参数</li>
<li>模型相同，主流用法，各设备梯度不同，需梯度同步机制
<ul>
<li>PRC 通信方式（Parameter server，Trainer）</li>
<li>NCCL2 通信方式（Collective）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="08-训练调试与优化">08 训练调试与优化<a href="#08-训练调试与优化" class="hash-link" aria-label="08 训练调试与优化的直接链接" title="08 训练调试与优化的直接链接">​</a></h4>
<ul>
<li>优化思路的五个关键环节
<ul>
<li>（1）计算分类准确率，观测模型训练效果（交叉熵 VS 准确率）</li>
<li>（2）检查模型训练过程，识别潜在问题（打印、定位）</li>
<li>（3）加入校验或测试，更好评价模型效果（三集合，欠拟合、过拟合）</li>
<li>（4）加入正则化项，避免模型过拟合（整体/局部参数 + 正则化项）
<ul>
<li>防过拟合
<ul>
<li>加入正则化项：增加了模型在训练集上的损失</li>
<li>暂退法 Dropout：每次迭代，随机丢掉（屏蔽）每层若干神经元，用余下神经元继续训练</li>
</ul>
</li>
</ul>
</li>
<li>（5）可视化分析（打印 Loss VS matplotlib、VisualDL）</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="09-恢复训练">09 恢复训练<a href="#09-恢复训练" class="hash-link" aria-label="09 恢复训练的直接链接" title="09 恢复训练的直接链接">​</a></h4>
<ul>
<li>需求：训练过程主动或被动的中断</li>
<li>保存和加载模型
<ul>
<li>预测场景：只保存模型参数</li>
<li>恢复训练场景：保存模型参数、优化器参数</li>
</ul>
</li>
<li>效果：恢复训练与未中断训练的效果完全一致</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="10-动转静部署">10 动转静部署<a href="#10-动转静部署" class="hash-link" aria-label="10 动转静部署的直接链接" title="10 动转静部署的直接链接">​</a></h4>
<ul>
<li>保存和加载模型之后，需对接部署工具，涉及动静态图概念
<ul>
<li>声明式编程（静态图）：先编译后执行（全局）</li>
<li>命令式编程（动态图）：解析式地执行（交互）</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>2023/03/15 19:12:25 2h36min 2.1-2.5</li>
<li>2023/03/15 23:44:54 3h30min 2.6-2.9</li>
<li>2023/03/16 17:27:56 2.10</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="03-计算机视觉基础">03 计算机视觉基础<a href="#03-计算机视觉基础" class="hash-link" aria-label="03 计算机视觉基础的直接链接" title="03 计算机视觉基础的直接链接">​</a></h3>
<p>​		本章简要介绍了计算机视觉的内容、应用及主要挑战，结合若干子任务，分别从任务目标、模型框架、基本原理、代码实践等方面展开了分析。</p>
<p>​		正如人的大部分信息通过视觉获取，我们也希望让机器学会如何去 “看”。</p>
<ul>
<li>因此，可以定义如下六种 “看” 的行为：
<ul>
<li>图像分类（分类；CNN、Transformer）</li>
<li>目标检测（标注位置；Anchor based、Anchor free、Transformer）</li>
<li>图像语义识别（分割、tag；细粒度）</li>
<li>实例分析 OCR（文字识别；两阶段、端到端算法、图网络）</li>
<li>视频分析（分类、分割、时空、时序；帧联系）</li>
<li>图像生成（GAN；修复、迁移、生成）</li>
</ul>
</li>
<li>概念补充
<ul>
<li>全连接/多层感知机</li>
<li>卷积（互相关运算）</li>
<li>池化（输出综合置换）</li>
<li>dropout（随机删除部分神经元）</li>
</ul>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="04-计算机视觉基础案例实践">04 计算机视觉基础案例实践<a href="#04-计算机视觉基础案例实践" class="hash-link" aria-label="04 计算机视觉基础案例实践的直接链接" title="04 计算机视觉基础案例实践的直接链接">​</a></h3>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="05-更复杂的计算机视觉任务目标检测">05 更复杂的计算机视觉任务：目标检测<a href="#05-更复杂的计算机视觉任务目标检测" class="hash-link" aria-label="05 更复杂的计算机视觉任务：目标检测的直接链接" title="05 更复杂的计算机视觉任务：目标检测的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="01-目标检测基本概念和-yolov3-设计思想">01 目标检测基本概念和 YOLOv3 设计思想<a href="#01-目标检测基本概念和-yolov3-设计思想" class="hash-link" aria-label="01 目标检测基本概念和 YOLOv3 设计思想的直接链接" title="01 目标检测基本概念和 YOLOv3 设计思想的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" alt="img" src="/Notes/assets/images/183dc8e1df224df2b223f4e80b68d42c3d746f339a084c5a9f3942fba3475988-4506906ff79b5081eb50cfb0481553de.png" width="553" height="191" class="img_O9Fa"></p>
<ul>
<li>图像分类处理基本流程（如上图）：
<ul>
<li>输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em"></span><span class="mrel">⟶</span></span></span></span> 图像特征提取（卷积网络） <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em"></span><span class="mrel">⟶</span></span></span></span> 特征表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em"></span><span class="mrel">⟶</span></span></span></span> 分类器 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em"></span><span class="mrel">⟶</span></span></span></span> 预测 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em"></span><span class="mrel">⟶</span></span></span></span> 选出概率最大类别</li>
</ul>
</li>
<li>背景：<strong>目标检测无法按照此流程进行（流程无法体现不同目标的区别）</strong></li>
<li>思路：
<ul>
<li>假设存在某种方式，使得在输入图片的基础上，生成一系列可能包含物体的区域，称为<strong>候选区域</strong>（Region Propposal, RP）。在一张图上，可以生成若干个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>P</mi></mrow><annotation encoding="application/x-tex">RP</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">RP</span></span></span></span>。对每一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>P</mi></mrow><annotation encoding="application/x-tex">RP</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">RP</span></span></span></span>，可以把它当作<strong>单独</strong>一幅图像，并使用图像<strong>分类</strong>模型进行处理，看它属于哪个类别或场景</li>
<li>关键：<strong>穷举解构图像，单独分类识别</strong></li>
<li>如何产生候选区域？
<ul>
<li>两点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 确定一个矩形框 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">AB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span></li>
<li>问题：穷举计算量，生成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>P</mi></mrow><annotation encoding="application/x-tex">RP</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">RP</span></span></span></span> 数目约为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><msup><mi>W</mi><mn>2</mn></msup><msup><mi>H</mi><mn>2</mn></msup></mrow><mn>4</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{W^2 H^2}{4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3629em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0179em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-2.931em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-2.931em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> ？</li>
</ul>
</li>
</ul>
</li>
<li><strong>工具：目标检测算法</strong>
<ul>
<li>需求 =&gt; 目标：产生候选区域的方法，提升候选区域分类效率</li>
<li><strong>Anchor-Based</strong>（Anchor 提取候选目标框，在特征图上的每一个点，对 Anchor 进行分类和回归）
<ul>
<li>两阶段检测算法（分段）
<ul>
<li>R-CNN 系列（<strong>Fast R-CNN</strong>、Faster R-CNN 等）</li>
<li>优劣：具有较优的精度，但是预测速度较慢</li>
</ul>
</li>
<li>单阶段检测算法（同时）
<ul>
<li>YOLO 系列（YOLOV2、YOLOv3、YOLOv4、PP-YOLO、PP-YOLOV2 等）</li>
<li>优劣：网络结构更加简单，检测速度快</li>
</ul>
</li>
<li>优劣：
<ul>
<li>手工设计 Anchor 需要考虑 Anchor 的数量、尺寸(长宽比)；</li>
<li>在特征图上像素点密集滑动会生成的检测框会存在大量负样本区域，就需要考虑正负样本不均衡的问题；</li>
<li>Anchor 的设计导致网络超参数变多，模型学习比较困难；</li>
<li>更换不同的数据集需要重新调整 Anchor。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Anchor-Free</strong>（不再使用预先设定Anchor，通常通过预测目标的中心或角点，对目标进行检测）
<ul>
<li>基于中心区域预测的方法（FCOS、CenterNet等）</li>
<li>基于多关键点联合表达的方法（CorNert、RepPoints 等）</li>
<li>优劣：
<ul>
<li>不需设计 Anchor，模型更简单，耗时更少，但精度比 Anchor-Based 低</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="img" src="/Notes/assets/images/ada190d940164471a0d6202aa1011f51eed709293e774e7a8fb474fb91aaffaa-5e53fe247d4a94b59d31da8ebfc3e904.png" width="465" height="255" class="img_O9Fa"></p>
<ul>
<li>
<p>概念</p>
<ul>
<li>
<p><strong>边界框（Bounding Box，BBox）</strong></p>
<ul>
<li>真实框（ground truth box）</li>
<li>预测框（prediction box）</li>
<li><strong>注意区分两种格式</strong>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>y</mi><mi>x</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">xyxy</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span> （ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><msub><mi>y</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1 y_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 左上角， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub><msub><mi>y</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x_2 y_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 右下角）</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>y</mi><mi>w</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">xywh</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mord mathnormal">h</span></span></span></span> （ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">x y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span> 中心，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">wh</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mord mathnormal">h</span></span></span></span> 宽高）</li>
</ul>
</li>
<li>输出：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>L</mi><mo separator="true">,</mo><mi>P</mi><mo separator="true">,</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[L, P, x_1, y_1, x_2, y_2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">L</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span></span></span></span> 是类别标签，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span> 是物体属于该类别的概率</li>
</ul>
</li>
<li>
<p><strong>锚框（Anchor box）</strong></p>
<ul>
<li>定义：指人为预先设定好比例的一组候选框集合（也可自动生成）</li>
<li>那么，如何对初始锚框进行合理的调整呢？
<ul>
<li>固定的，需微调，模型可训练习得微调方法</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>交并比（Intersection of Union，IoU）</strong></p>
<ul>
<li>用途：衡量锚框与真实框之间的关系</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>o</mi><mi>U</mi><mo>=</mo><mfrac><mrow><mi>A</mi><mo>∩</mo><mi>B</mi></mrow><mrow><mi>A</mi><mo>∪</mo><mi>B</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">IoU = \frac{A \cap B}{A \cup B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10903em">U</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="mbin mtight">∪</span><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="mbin mtight">∩</span><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> ，即相交量比并集总量</li>
</ul>
<p><img decoding="async" loading="lazy" alt="img" src="/Notes/assets/images/c2095c01997044f8a054d676ab585f3beed4400961ea40379771a1fd6d8bf2ea-ea8af51fc39ca5d1817545a2029b1a5c.png" width="475" height="295" class="img_O9Fa"></p>
<ul>
<li>思考：根据坐标表示的交并比计算公式是否可完全覆盖？</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20230327041228472" src="/Notes/assets/images/image-20230327041228472-af92b165e2950d2d66c67cb36d6d8ee1.png" width="838" height="542" class="img_O9Fa"></p>
<ul>
<li><strong>非极大值抑制（Non-maximum suppression，NMS）</strong>
<ul>
<li>用途：消除重叠较大的冗余预测框</li>
<li>原理：只选出得分最高的那个预测框，其余丢弃</li>
<li>如何判断两个预测框对应的是同一个物体呢，标准该怎么设置？
<ul>
<li>如果两个预测框的类别一样，而且他们的位置重合度比较大，则可以认为他们是在预测同一个目标，继而与设定的超参阈值进行比较，大于阈值则舍弃（YOLOv3 默认 0.5）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>2023/03/27 4:29:51</p>
</li>
</ul>
<hr>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="02-单阶段目标检测模型-yolov3">02 单阶段目标检测模型 YOLOv3<a href="#02-单阶段目标检测模型-yolov3" class="hash-link" aria-label="02 单阶段目标检测模型 YOLOv3的直接链接" title="02 单阶段目标检测模型 YOLOv3的直接链接">​</a></h4>
<hr>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="03-目标检测-yolov3-实战叶病虫害检测">03 目标检测 YOLOv3 实战：叶病虫害检测<a href="#03-目标检测-yolov3-实战叶病虫害检测" class="hash-link" aria-label="03 目标检测 YOLOv3 实战：叶病虫害检测的直接链接" title="03 目标检测 YOLOv3 实战：叶病虫害检测的直接链接">​</a></h4>
<ul>
<li>问题汇总
<ul>
<li>作业中的 Anchor 是手动定义的，如何通过算法习得？</li>
</ul>
</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="06-自然语言处理基础">06 自然语言处理基础<a href="#06-自然语言处理基础" class="hash-link" aria-label="06 自然语言处理基础的直接链接" title="06 自然语言处理基础的直接链接">​</a></h3>
<p>​		第一节介绍了自然语言处理（Natural Language Processing，NLP）在人机通信当中的意义，并且介绍了 NLP 的应用场景，如翻译机、语音助手、搜索、推荐等。同时，还介绍了 NLP 中的深度学习技术的发展历程与发展方向，强调以 BERT 为分水岭的预训练模型技术在 NLP 的核心地位，而当下大模型的应用场景也愈加广泛。最后，介绍了 NLP 发展的主要挑战及应对方法。</p>
<p>​		NLP 从 1950 年前后兴起，到 1966 年符号主义的奠定而进一步发展，随之 1980 年连接主义的兴起而引入了新的活力，继 2006 年深度学习的成果而焕发了新一轮春天。而 2022年 NLP 领域的 ChatGPT 浪潮又引起了大众空前的持续、广泛的思考。</p>
<p><img decoding="async" loading="lazy" alt="image-20230327160813003" src="/Notes/assets/images/image-20230327160813003-48191c18aaf834f12d5bd450ef613a87.png" width="1086" height="571" class="img_O9Fa"></p>
<p>​		NLP 的发展历程，围绕着<strong>两大挑战</strong>展开，一是<strong>语言学挑战</strong>，例如同义词的判断、语言歧义、不同语言的分词方法、多轮对话中的指代和省略等等；二是<strong>计算挑战</strong>，例如自然语言本身的编码形式与计算机的二进制语言、自然语言编码本身并非数字，无法直接计算。</p>
<p>​		在解决这些挑战的过程中， NLP 形成了<strong>两大技术划分</strong>，一是<strong>理解</strong>，另一是<strong>生成</strong>。“理解” 将给定文本分析、计算，产生计算机可以理解和处理的统一形式，主要解决 “词法、句法、语义、回指” 这四种歧义性；“生成” 将计算机产生的语义表达结果转化为人类可以读懂的自然语言过程，大致可以分为三个阶段 “文本规划、语句规划、实现”。换句话说，“理解” 是让计算机去理解人类语言，“生成” 是让计算机去表达人类语言。</p>
<p>​		第二节介绍了语言模型及其局限性，提出了目前使用更为广泛的神经网络语言模型，讲述了词向量、词方法实现语言模型的基本思路，同时讲解了经典的词向量算法 CBOW 和 Skip-gram 的原理、结构、实现、问题与改进，最后提及了预训练模型对于 NLP 的可操性。</p>
<p>​		语言模型（N-gram）的含义，通常是指：<strong>语句语序出现可能性最大的概率模型</strong>。由于语言模型存在局限：无法建模更远的关系、词相关性不足、泛化能力不高，继而又出现了神经网络语言模型（NNLM）。</p>
<p><img decoding="async" loading="lazy" alt="image-20230327172827091" src="/Notes/assets/images/image-20230327172827091-6730f2786d9c6886571293a4598ba0bb.png" width="1841" height="957" class="img_O9Fa"></p>
<p>​		前面提到 NLP 的计算编码挑战，为了规范化自然语言，便有了 “词向量（Word Embedding）” 这一抽象结构，词向量是一种表示自然语言单词的方法，把每一个词都表示为一个 n 维空间内的点，即一个高维空间内的向量，从而将自然语言计算问题转化为向量计算问题（相当于高维空间里的降维操作，未理解降维关系）。</p>
<p>​		为了实现词向量，需要思考两个问题：如何把词转换为向量？如何让向量具有语义信息？神经网络计算需要大量算力，通常借助 GPU 等硬件的算力，一般以张量（Tensor）为单位展开，因此实际我们需要把 Embedding lookup 过程转换为张量计算。而利用单词的上下文信息，可以帮助消除单词的歧义，即可以赋予向量语义信息（但这里涉及一个启动标签的问题？其实不然）。</p>
<p><img decoding="async" loading="lazy" alt="image-20230327173801631" src="/Notes/assets/images/image-20230327173801631-550c2a6847b77604bc65dadce6e31629.png" width="1693" height="944" class="img_O9Fa"></p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="07-自然语言处理模型的网络结构">07 自然语言处理模型的网络结构<a href="#07-自然语言处理模型的网络结构" class="hash-link" aria-label="07 自然语言处理模型的网络结构的直接链接" title="07 自然语言处理模型的网络结构的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="01-nlp-经典神经网络">01 NLP 经典神经网络<a href="#01-nlp-经典神经网络" class="hash-link" aria-label="01 NLP 经典神经网络的直接链接" title="01 NLP 经典神经网络的直接链接">​</a></h4>
<p>​		算法上，本节介绍了 NLP 经典的神经网络，如循环（递归）神经网络 RNN、长短时记忆网络 LSTM，以及基于混淆矩阵的网络评估方法。应用上，介绍了情感分析在电商评价与电影评论当中的角色定位。技术上，介绍了情感分析的两种建模方式，分别为加和平均法、序列建模法，同时介绍了采用多个 LSTM 单元接一个全连接层，结果由 Softmax 处理实现输出的模型架构。</p>
<p><img decoding="async" loading="lazy" alt="image-20230327202937477" src="/Notes/assets/images/image-20230327202937477-c7f9062a69caf87054954b9b4febca52.png" width="1767" height="751" class="img_O9Fa"></p>
<p>​		最后，介绍了使用 Paddle 基于 NLP 经典入门数据集 IMDB 进行情感分析的完整实例，其中 seq2vec 实现了降维操作。</p>
<p><img decoding="async" loading="lazy" alt="image-20230327213224027" src="/Notes/assets/images/image-20230327213224027-197965d75636deb66a56a438343938b4.png" width="1734" height="917" class="img_O9Fa"></p>
<hr>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="02-transformer网络结构">02 Transformer网络结构<a href="#02-transformer网络结构" class="hash-link" aria-label="02 Transformer网络结构的直接链接" title="02 Transformer网络结构的直接链接">​</a></h4>
<p>​		本节介绍了具有里程碑意义的新模型 Transformer，这是一种自注意力模型，解决了 RNN 长距离依赖、不能进行并行计算的问题。</p>
<p><img decoding="async" loading="lazy" alt="image-20230327213832898" src="/Notes/assets/images/image-20230327213832898-2f3a6b001f5adf946f6519abfff2afb1.png" width="1863" height="866" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20230327213832898" src="/Notes/assets/images/image-20230327213832898-1680011746354-2f3a6b001f5adf946f6519abfff2afb1.png" width="1863" height="866" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20230327214105866" src="/Notes/assets/images/image-20230327214105866-25960147fb4c9fd985353e4ac7c7ae61.png" width="1874" height="846" class="img_O9Fa"></p>
<p>​		因为自注意力模型得到的结果值通常比较大，需要归一化处理，而结果又涉及概率，除以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><msub><mi>D</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{D_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-0.1883em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8517em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.8117em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1883em"><span></span></span></span></span></span></span></span></span> 可以使得数据变集中；另外，考虑到除法运算之后得到的是数值，因此为了提取系数，用 Softmax 处理。</p>
<p>​		除了自注意力模型之外，还有 Seq2Seq 模型，指的是从序列到序列的模型，常用在语音和语言任务。Seq2Seq 模型往往采用编码器-解码器（Encoder-Decoder）的结构设计，主要用于异步的序列到序列的深度学习任务，这是一种相当重要的结构，应用十分广泛。其中包含了自控制结构，编码器用于处理输入，将向量传给解码器，解码器则逐字逐句生成输出，并且解码器内部可层层衔接，进一步处理解码器之间的输出，形成具有深度的网络结构。</p>
<p><img decoding="async" loading="lazy" alt="image-20230328145016459" src="/Notes/assets/images/image-20230328145016459-b6dea5dfce203774973930f635c344a3.png" width="1846" height="761" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20230328145254320" src="/Notes/assets/images/image-20230328145254320-efc182e1242c4f4afdb05c5aa2cfdd8a.png" width="1863" height="859" class="img_O9Fa"></p>
<hr>
<p>​		接着，介绍了 Transformer 的网络结构（如下图所示）。其中，第八章讲述的 BERT 模型，满足左侧的结构，而像 GPT 模型，则需要加上右侧的结构。</p>
<p><img decoding="async" loading="lazy" alt="image-20230328150548932" src="/Notes/assets/images/image-20230328150548932-b964a9c57746e958796f6ff9d9a675f6.png" width="1754" height="963" class="img_O9Fa"></p>
<p>​		假设 Transformer Encoder 和 Decoder 部分均为六层网络结构，则具体结构如下图。</p>
<p><img decoding="async" loading="lazy" alt="image-20230328155044524" src="/Notes/assets/images/image-20230328155044524-60e5d12604372781a584b0f6df97cd6b.png" width="1757" height="913" class="img_O9Fa"></p>
<p>​		可以看到， Transformer Encoder 结构有一层嵌入层、若干层编码层。嵌入层生成特征表示，编码层生成当前的特征编码向量，编码层采用多头注意力机制实现，利用正余弦函数的周期性变化，对每个 token （序列单词）进行位置信息表征。</p>
<p><img decoding="async" loading="lazy" alt="image-20230328161850062" src="/Notes/assets/images/image-20230328161850062-93f4a6afdd9ac3ec407028a6fdb11edf.png" width="1766" height="951" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20230328162344338" src="/Notes/assets/images/image-20230328162344338-f3445a10f0450d1df42ed72484e9e17c.png" width="1855" height="881" class="img_O9Fa"></p>
<p>​		多头注意力机制，本质是多组相互独立的自注意力计算（即多组 “头”）的组合，每组根据输入向量序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">X</span></span></span></span>，获得相应的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mtext>、</mtext><mi>K</mi><mtext>、</mtext><mi>V</mi></mrow><annotation encoding="application/x-tex">Q、K、V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span><span class="mord cjk_fallback">、</span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mord cjk_fallback">、</span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span> 向量，最后计算均值，获得一组用于多头计算的向量，即将各头的结果融合，得到最终输出向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span></span></span></span>。</p>
<p><img decoding="async" loading="lazy" alt="image-20230328162427395" src="/Notes/assets/images/image-20230328162427395-82136bd302da893213cf5f1c18ad5450.png" width="1856" height="897" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20230328162529838" src="/Notes/assets/images/image-20230328162529838-c0e172c46f3cb97e1176c6367377ca61.png" width="1877" height="913" class="img_O9Fa"></p>
<p>​		多头注意力计算之后，结果由 Layer Normalization 进行归一化处理，LN 方法很适合 NLP 模型。接着，自下而上观察目前的结构或处理机制，都是线性的，这会导致结果对于可能的非线性情况泛化能力减弱，于是引入 Feed Forward 进行非线性处理，模型性能的提升可参考相关论文。</p>
<p><img decoding="async" loading="lazy" alt="image-20230328162610397" src="/Notes/assets/images/image-20230328162610397-81621ba55bb91bfae182ab4bc2cb0a3c.png" width="1814" height="954" class="img_O9Fa"></p>
<p>​		最后，数据经由加与规范层（Add &amp; Norm）处理，引入残差连接和层规范组件，残差块通过跨层短接的方式，使得信息向前传播更快，梯度向后传播更快，从而降低了随着网络加深带来的模型过拟合风险。相关的内容，可以通过研究模型设计的思路，逐步拆解组件而加深理解。</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_QJwc" id="08-自然语言处理任务的新范式预训练语言模型">08 自然语言处理任务的新范式：预训练语言模型<a href="#08-自然语言处理任务的新范式预训练语言模型" class="hash-link" aria-label="08 自然语言处理任务的新范式：预训练语言模型的直接链接" title="08 自然语言处理任务的新范式：预训练语言模型的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="01-预训练语言模型-bert">01 预训练语言模型 BERT<a href="#01-预训练语言模型-bert" class="hash-link" aria-label="01 预训练语言模型 BERT的直接链接" title="01 预训练语言模型 BERT的直接链接">​</a></h4>
<p>​		本节讲述了预训练模型（pre-training language model）对于自然语言处理的范式革命，引出了**预训练（pre-training）+微调（fine-tuning）**的 NLP 新范式。而具有里程碑意义的是 2018 年提出的预训练 BERT，BERT 名字来源于美国的一档儿童教育节目《芝麻街》，就像 Transformer 来源于《变形金刚》一样，AI 算法的命名似乎走上了戏剧化的道路。</p>
<p>​		这种新范式，允许我们采用首先在（超）大规模语料库上进行训练的开源模型，而后基于该预训练模型进行微调，并且在下游任务当中获得更好的表现。换句话说，开源预训练模型提供了<strong>通用的无监督数据</strong>，提高了<strong>特定任务下的有监督数据</strong>开发调优的可能性。目前，BERT 是主流的预训练模型。</p>
<p><img decoding="async" loading="lazy" alt="image-20230328165810160" src="/Notes/assets/images/image-20230328165810160-6936b05f502e659736e06f8c22fd09fd.png" width="1849" height="861" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20230328165918514" src="/Notes/assets/images/image-20230328165918514-7c277d793ae6a10089dd561447da2d45.png" width="1855" height="957" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20230328170518906" src="/Notes/assets/images/image-20230328170518906-ed211bbeaf685a904997a408ddb62ba2.png" width="1856" height="964" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20230328170638111" src="/Notes/assets/images/image-20230328170638111-6f816b3321bcbb99b23b7ca8b9112479.png" width="1662" height="787" class="img_O9Fa"></p>
<p>​		BERT 利用<strong>两个预训练任务 MLM 和 NSP</strong> 任务学习语言相关的知识。掩码语言模型（Masked Language Model，MLM），掩码策略以 “80% 替换 Mask token、10% 随机替换为其他词、10% 保持不变” 的比例进行分配；下一个句子预测（Next Sentence Prediction，NSP），部分无关句子拼接生成句子对，部分按照原文语序，通过判断两句话在原文中是否前后相邻，实现语序识别与训练。总言之，MLM 基于<strong>单词替换策略</strong>形成语料库，NSP 基于<strong>句子乱序策略</strong>形成语料库。</p>
<p>​		最后，比较重要的是<strong>预训练模型的范式表</strong>。</p>
<p><img decoding="async" loading="lazy" alt="image-20230328175517429" src="/Notes/assets/images/image-20230328175517429-1079aa55024024606fefb3d0191c4e2d.png" width="1691" height="763" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20230328180232831" src="/Notes/assets/images/image-20230328180232831-98de01b4ee11f9343ef523531d4fec67.png" width="1794" height="842" class="img_O9Fa"></p>
<p><img decoding="async" loading="lazy" alt="image-20230328180423759" src="/Notes/assets/images/image-20230328180423759-c5c9913ebf0772eab4267f9ceb9e3a75.png" width="1834" height="863" class="img_O9Fa"></p>
<ul>
<li>这里需再次复盘</li>
</ul>
<hr>
<h4 class="anchor anchorWithStickyNavbar_QJwc" id="02-nlp-主流任务和快速实践">02 NLP 主流任务和快速实践<a href="#02-nlp-主流任务和快速实践" class="hash-link" aria-label="02 NLP 主流任务和快速实践的直接链接" title="02 NLP 主流任务和快速实践的直接链接">​</a></h4>
<p>​		本节介绍了 NLP 领域基于 BERT 的四种经典任务，分别是：分类式任务、问答式任务、序列标注式任务、生成式任务。最后讲解了基于 BERT 实现文本匹配的完整实例。</p>
<p><img decoding="async" loading="lazy" alt="image-20230328181645776" src="/Notes/assets/images/image-20230328181645776-e0160af1e35d65b3739b28c851bc08a3.png" width="1769" height="842" class="img_O9Fa"></p>
<p>​		具体任务机制如下：</p>
<ul>
<li>分类式任务（文本分类）
<ul>
<li>句对分类任务（两段话）、单句分类任务（一段话）</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20230328181837901" src="/Notes/assets/images/image-20230328181837901-ead948e36337079aa5fdaf7841a81574.png" width="1840" height="826" class="img_O9Fa"></p>
<ul>
<li>问答式任务（阅读理解）
<ul>
<li>问题与文档拼接，从输出的序列向量定位答案起始位置</li>
<li>（如果本身没有答案，这种方法是否仍有效？）</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20230328183305216" src="/Notes/assets/images/image-20230328183305216-44f1c1df9bde33b4d46282bf1a4e1109.png" width="1705" height="821" class="img_O9Fa"></p>
<ul>
<li>序列标注式任务（命名实体识别）
<ul>
<li>基于文本分析，打标签</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="image-20230328183344159" src="/Notes/assets/images/image-20230328183344159-6d1f75c0bbe413403962a42e79d646d7.png" width="1722" height="826" class="img_O9Fa"></p>
<ul>
<li>2023/03/28 23:30:07</li>
</ul>
<hr></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/Notes/docs/category/paddle-零基础深度学习第二版"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">Paddle 零基础深度学习（第二版）</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Notes/docs/paddle_deep_learning/task01"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">task01</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_G4nv thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#task00-paddle-深度学习总结" class="table-of-contents__link toc-highlight">Task00 Paddle 深度学习总结</a></li><li><a href="#00-意义" class="table-of-contents__link toc-highlight">00 意义</a></li><li><a href="#01-深度学习简介" class="table-of-contents__link toc-highlight">01 深度学习简介</a></li><li><a href="#02-一个案例吃透深度学习" class="table-of-contents__link toc-highlight">02 一个案例吃透深度学习</a></li><li><a href="#03-计算机视觉基础" class="table-of-contents__link toc-highlight">03 计算机视觉基础</a></li><li><a href="#04-计算机视觉基础案例实践" class="table-of-contents__link toc-highlight">04 计算机视觉基础案例实践</a></li><li><a href="#05-更复杂的计算机视觉任务目标检测" class="table-of-contents__link toc-highlight">05 更复杂的计算机视觉任务：目标检测</a></li><li><a href="#06-自然语言处理基础" class="table-of-contents__link toc-highlight">06 自然语言处理基础</a></li><li><a href="#07-自然语言处理模型的网络结构" class="table-of-contents__link toc-highlight">07 自然语言处理模型的网络结构</a></li><li><a href="#08-自然语言处理任务的新范式预训练语言模型" class="table-of-contents__link toc-highlight">08 自然语言处理任务的新范式：预训练语言模型</a></li></ul></div></div></div></div></main></div></div></div></div>
</body>
</html>